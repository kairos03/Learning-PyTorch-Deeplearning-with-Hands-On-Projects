{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3 트렌스포머를 이용한 객체명 인식기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25463,
     "status": "ok",
     "timestamp": 1702811585572,
     "user": {
      "displayName": "신은섭",
      "userId": "08402895350193765155"
     },
     "user_tz": -540
    },
    "id": "TnqZEBvTM0vC",
    "outputId": "da3fba3f-2b2f-4b9f-bbfa-2db8f1d326cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-17 11:12:52.997091: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-17 11:12:52.997152: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-17 11:12:52.999030: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-17 11:12:53.009613: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-17 11:12:54.352625: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-17 11:12:55.817615: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-17 11:12:55.818051: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-17 11:12:55.818228: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "Collecting ko-core-news-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ko_core_news_sm-3.6.0/ko_core_news_sm-3.6.0-py3-none-any.whl (14.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ko-core-news-sm==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (0.10.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (1.10.13)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (67.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->ko-core-news-sm==3.6.0) (2.1.3)\n",
      "Installing collected packages: ko-core-news-sm\n",
      "Successfully installed ko-core-news-sm-3.6.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ko_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install -q torchinfo spacy\n",
    "!python -m spacy download ko_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KeB6FPC9Mudf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchinfo import summary\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1702811588438,
     "user": {
      "displayName": "신은섭",
      "userId": "08402895350193765155"
     },
     "user_tz": -540
    },
    "id": "2ILhaoGbMwY9",
    "outputId": "cccb728e-ea3d-404f-8201-5fefa89c10a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True cuda\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if is_cuda else \"cpu\")\n",
    "print(is_cuda, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4gNlXBmMxXJ"
   },
   "outputs": [],
   "source": [
    "seed = 827\n",
    "random.seed(seed)         # python seed\n",
    "np.random.seed(seed)      # numpy seed\n",
    "torch.manual_seed(seed)   # torch seed\n",
    "if device == 'cuda':\n",
    "  torch.cuda.manual_seed_all(seed)  # gpu seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aq2lPRHSKBF8"
   },
   "source": [
    "### 3.2 객체명 인식 데이터\n",
    "NAVER NLP 챌린지 데이터셋\n",
    "- 14 종류의 Annotated Entities\n",
    "- 인물(PER), 학문분야(FLD), 인공물(AFW), 기관 및 단체(ORG), 지역명(LOC), 문명 및 문화 (CVL), 날짜(DAT), 시간(TIM), 숫자(NUM), 사건사고 및 행사(EVT), 동물(ANM), 식물(PLT), 금속/암석/화학물질(MAT), 의학용어/IT관련 용어(TRM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1213,
     "status": "ok",
     "timestamp": 1702811589646,
     "user": {
      "displayName": "신은섭",
      "userId": "08402895350193765155"
     },
     "user_tz": -540
    },
    "id": "lBBFX7J_IbVP",
    "outputId": "c74fd082-68ac-4c96-9bc6-0c279c34b1c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-17 11:13:08--  https://raw.githubusercontent.com/naver/nlp-challenge/master/missions/ner/data/train/train_data\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16945023 (16M) [text/plain]\n",
      "Saving to: ‘train_data’\n",
      "\n",
      "train_data          100%[===================>]  16.16M  --.-KB/s    in 0.07s   \n",
      "\n",
      "2023-12-17 11:13:09 (226 MB/s) - ‘train_data’ saved [16945023/16945023]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/naver/nlp-challenge/master/missions/ner/data/train/train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Geclhj5fAhm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def train_iter(file_path=\"train_data\", train=True):\n",
    "  sentences = []\n",
    "  sentence = [[], [], []]\n",
    "  for line in open(file_path, encoding=\"utf-8\"):\n",
    "    line = line.strip()\n",
    "    if line == \"\":\n",
    "      sentences.append(sentence)\n",
    "      sentence = [[], [], []]\n",
    "    else:\n",
    "      idx, ejeol, ner_tag = line.split(\"\\t\")\n",
    "      # idx는 0부터 시작하도록\n",
    "      sentence[0].append(int(idx))\n",
    "      sentence[1].append(ejeol)\n",
    "      sentence[2].append(ner_tag)\n",
    "  return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1773,
     "status": "ok",
     "timestamp": 1702811591416,
     "user": {
      "displayName": "신은섭",
      "userId": "08402895350193765155"
     },
     "user_tz": -540
    },
    "id": "ONfl124GI993",
    "outputId": "6b04ad45-607a-447f-e080-632cd0cfb2f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       " ['7승', '25패는', '상트페테르부르크가', '역대', '월드리그에', '출진한', '분별', '최선의', '성적이다', '.'],\n",
       " ['NUM_B', 'NUM_B', 'LOC_B', '-', 'EVT_B', '-', '-', '-', '-', '-']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = train_iter()\n",
    "dl[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1702811591416,
     "user": {
      "displayName": "신은섭",
      "userId": "08402895350193765155"
     },
     "user_tz": -540
    },
    "id": "YUnRcqClJGK3",
    "outputId": "86d89a1b-df8c-4c19-a698-1efef2ab24b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JMGlFaEvPhmk"
   },
   "outputs": [],
   "source": [
    "indices, sentences, labels = zip(*dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1702811591416,
     "user": {
      "displayName": "신은섭",
      "userId": "08402895350193765155"
     },
     "user_tz": -540
    },
    "id": "tVH2s2Eeptz0",
    "outputId": "e16a89a1-bf0a-49ce-a55f-28105e7ae8c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['비토리오', '양일', '만에', '영사관', '감호', '용퇴,', '항룡', '압력설', '의심만', '가율']\n",
      "['PER_B', 'DAT_B', '-', 'ORG_B', 'CVL_B', '-', '-', '-', '-', '-']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Vd3EFj4L0LC"
   },
   "source": [
    "네이버 NLP 챌린지 데이터셋은 BIO시스템을 따르는 데이터셋입니다. _B는 Begin의 약자로 해당 단어가 시작할 때, _I는 Inside의 약자로 단어 중간일 때를 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WCAsDILAOwYW"
   },
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "text_vocab = build_vocab_from_iterator(sentences,\n",
    "                                       min_freq=1,\n",
    "                                       specials=special_symbols,\n",
    "                                       special_first=True)\n",
    "text_vocab.set_default_index(text_vocab[\"<unk>\"])\n",
    "\n",
    "ner_vocab = build_vocab_from_iterator(labels,\n",
    "                                      min_freq=1,\n",
    "                                      specials=special_symbols,\n",
    "                                      special_first=True)\n",
    "ner_vocab.set_default_index(text_vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1702811593892,
     "user": {
      "displayName": "신은섭",
      "userId": "08402895350193765155"
     },
     "user_tz": -540
    },
    "id": "vvEnz5gWp_hq",
    "outputId": "1df127df-9772-45f2-f97e-076bd7bd7555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', '<bos>', '<eos>', '-', 'CVL_B', 'NUM_B', 'PER_B', 'ORG_B', 'DAT_B', 'LOC_B', 'TRM_B', 'EVT_B', 'NUM_I', 'DAT_I', 'ANM_B', 'EVT_I', 'PER_I', 'ORG_I', 'AFW_B', 'CVL_I', 'TRM_I', 'TIM_B', 'FLD_B', 'AFW_I', 'TIM_I', 'PLT_B', 'MAT_B', 'LOC_I', 'ANM_I', 'FLD_I', 'MAT_I', 'PLT_I']\n"
     ]
    }
   ],
   "source": [
    "print(ner_vocab.get_itos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1702811593892,
     "user": {
      "displayName": "신은섭",
      "userId": "08402895350193765155"
     },
     "user_tz": -540
    },
    "id": "zRYMQ6nPPyeE",
    "outputId": "c1b27ca5-eb7f-43f2-fff1-beb1fc8dbd7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2599, 6351, 1260, 34688, 2807, 0, 0, 30]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vocab([\"오늘도\", \"빠지지\", \"말고\", \"프로젝트로\", \"시작하는\", \"파이토치\", \"공부하자\",\"!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qTOgj_aUW8z4"
   },
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "  def __init__(self, file_path=\"train_data\"):\n",
    "    sentences = []\n",
    "    sentence = [[], []]\n",
    "    for line in open(file_path, encoding=\"utf-8\"):\n",
    "      line = line.strip()\n",
    "      if line == \"\":\n",
    "        sentences.append(sentence)\n",
    "        sentence = [[], []]\n",
    "      else:\n",
    "        idx, ejeol, ner_tag = line.split(\"\\t\")\n",
    "        sentence[0].append(ejeol)\n",
    "        sentence[1].append(ner_tag)\n",
    "\n",
    "    self.texts, self.labels = zip(*sentences)\n",
    "\n",
    "  def __getitem__(self, i):\n",
    "    return self.texts[i], self.labels[i]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2805,
     "status": "ok",
     "timestamp": 1702811596696,
     "user": {
      "displayName": "신은섭",
      "userId": "08402895350193765155"
     },
     "user_tz": -540
    },
    "id": "YBE2_-ZQer4K",
    "outputId": "4c095118-a6a4-4894-9095-639e973bf4b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['비토리오', '양일', '만에', '영사관', '감호', '용퇴,', '항룡', '압력설', '의심만', '가율'],\n",
       " ['PER_B', 'DAT_B', '-', 'ORG_B', 'CVL_B', '-', '-', '-', '-', '-'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_dataset = NERDataset()\n",
    "ner_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1702811596697,
     "user": {
      "displayName": "신은섭",
      "userId": "08402895350193765155"
     },
     "user_tz": -540
    },
    "id": "FzmopJgYv9tT",
    "outputId": "ccefc7af-e682-449c-bde9-66611c8e0722"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(text) for text in ner_dataset.texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4386,
     "status": "ok",
     "timestamp": 1702811601080,
     "user": {
      "displayName": "신은섭",
      "userId": "08402895350193765155"
     },
     "user_tz": -540
    },
    "id": "_dW-Ggq7XkXY",
    "outputId": "cc824c54-f4bd-46a4-d422-1610fed492a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72001 9000 8999\n"
     ]
    }
   ],
   "source": [
    "def get_dataset(train=0.8, val=0.1, random_seed=827):\n",
    "  origin = NERDataset()\n",
    "\n",
    "  torch.manual_seed(random_seed)\n",
    "  trainset, valset, testset = torch.utils.data.random_split(\n",
    "    origin,\n",
    "    (train, val, 1-train-val),\n",
    "  )\n",
    "\n",
    "  return trainset, valset, testset\n",
    "\n",
    "trainset, valset, testset = get_dataset()\n",
    "print(len(trainset), len(valset), len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1n5c8pRtcOb"
   },
   "outputs": [],
   "source": [
    "# 순차적인 작업들을 하나로 묶는 헬퍼 함수\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# BOS/EOS를 추가하고 입력 순서(sequence) 인덱스에 대한 텐서를 생성하는 함수\n",
    "def tensor_transform(token_ids):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# 출발어(src)와 도착어(tgt) 원시 문자열들을 텐서 인덱스로 변환하는 변형(transform)\n",
    "text_transforms = sequential_transforms(text_vocab, # 수치화(Numericalization)\n",
    "                                        tensor_transform) # BOS/EOS를 추가하고 텐서를 생성\n",
    "ner_transforms = sequential_transforms(ner_vocab,   # 수치화(Numericalization)\n",
    "                                        tensor_transform) # BOS/EOS를 추가하고 텐서를 생성\n",
    "\n",
    "# 데이터를 텐서로 조합(collate)하는 함수\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transforms(src_sample))\n",
    "        tgt_batch.append(ner_transforms(tgt_sample))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4R-O60D6Tk_i"
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(ner_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1702811601080,
     "user": {
      "displayName": "신은섭",
      "userId": "08402895350193765155"
     },
     "user_tz": -540
    },
    "id": "ExmLGAo3UM0L",
    "outputId": "14aa8e44-2c0c-4b77-f5b3-bae95c7ec75d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     2,      2,      2,      2],\n",
      "        [ 73762,     10, 124749,  15446],\n",
      "        [  8239, 262719,  61435, 115838],\n",
      "        [    87,   5261, 119193, 218342],\n",
      "        [ 81336,   1030,    296,    388],\n",
      "        [ 18246, 111342, 199356,  32484],\n",
      "        [256519,      4,  17581,   2418],\n",
      "        [ 34887,      3, 108843,  14186],\n",
      "        [242483,      1,  49384,   2622],\n",
      "        [263591,      1,  25990,  24028],\n",
      "        [ 37334,      1, 113884,      4],\n",
      "        [     3,      1,     48,      3],\n",
      "        [     1,      1, 317094,      1],\n",
      "        [     1,      1, 119460,      1],\n",
      "        [     1,      1,    131,      1],\n",
      "        [     1,      1,      4,      1],\n",
      "        [     1,      1,      3,      1]])\n",
      "tensor([[ 2,  2,  2,  2],\n",
      "        [ 7,  4,  6,  6],\n",
      "        [ 9,  4,  4,  6],\n",
      "        [ 4,  4,  6, 10],\n",
      "        [ 8,  6,  8,  4],\n",
      "        [ 5,  6,  7, 12],\n",
      "        [ 4,  4,  4,  4],\n",
      "        [ 4,  3,  6,  4],\n",
      "        [ 4,  1,  4,  4],\n",
      "        [ 4,  1,  4,  4],\n",
      "        [ 4,  1,  6,  4],\n",
      "        [ 3,  1,  4,  3],\n",
      "        [ 1,  1,  4,  1],\n",
      "        [ 1,  1,  6,  1],\n",
      "        [ 1,  1,  4,  1],\n",
      "        [ 1,  1,  4,  1],\n",
      "        [ 1,  1,  3,  1]])\n"
     ]
    }
   ],
   "source": [
    "for labels, texts in dataloader:\n",
    "  print(labels)\n",
    "  print(texts)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zC3ZdYk32AKF"
   },
   "source": [
    "### 3.4 트렌스포머 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6MIIChQqc8I"
   },
   "outputs": [],
   "source": [
    "# 입력 인덱스의 텐서를 해당하는 토큰 임베딩의 텐서로 변환하기 위한 헬퍼 모듈(Module)\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1702811601080,
     "user": {
      "displayName": "신은섭",
      "userId": "08402895350193765155"
     },
     "user_tz": -540
    },
    "id": "4sTmAds1qdw_",
    "outputId": "56d0b661-73de-459d-9e17-1098d100ff0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 8, 5, 4],\n",
      "        [4, 2, 1, 7],\n",
      "        [8, 6, 7, 4],\n",
      "        [5, 1, 3, 0],\n",
      "        [1, 8, 6, 6],\n",
      "        [3, 0, 7, 6],\n",
      "        [2, 0, 4, 2],\n",
      "        [9, 9, 5, 6],\n",
      "        [7, 3, 9, 7],\n",
      "        [8, 2, 7, 0]])\n",
      "torch.Size([10, 4, 32])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10\n",
    "emb_size = 32\n",
    "emb = TokenEmbedding(vocab_size, emb_size)\n",
    "\n",
    "sample = torch.randint(0, vocab_size, (seq_len, batch_size))\n",
    "print(sample)\n",
    "print(emb(sample).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OsWGpAllqWUL"
   },
   "outputs": [],
   "source": [
    "# 단어 순서 개념(notion)을 토큰 임베딩에 도입하기 위한 위치 인코딩(positional encoding)을 위한 헬퍼 모듈(Module)\n",
    "class PositionalEncoding(nn.Module):\n",
    "  def __init__(self, emb_size, dropout, maxlen=5000):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "    pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "\n",
    "    pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "    pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "    pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "    pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "    self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "  def forward(self, token_embedding):\n",
    "    token_embedding += self.pos_embedding[:token_embedding.size(0), :]\n",
    "    return self.dropout(token_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1702811601080,
     "user": {
      "displayName": "신은섭",
      "userId": "08402895350193765155"
     },
     "user_tz": -540
    },
    "id": "f-bxiyswqXSr",
    "outputId": "22c0925b-840d-48ce-f062-10ef96e44461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PE:     torch.Size([10, 1, 32])\n",
      "RESULT: torch.Size([10, 4, 32])\n"
     ]
    }
   ],
   "source": [
    "seq_len, batch_size, emb_size, dropout = 10, 4, 32, 0.1\n",
    "pe = PositionalEncoding(emb_size, dropout)\n",
    "\n",
    "sample = torch.rand((seq_len, batch_size, emb_size))\n",
    "x = pe(sample).shape\n",
    "print(\"PE:    \", pe.pos_embedding[:sample.size(0), :].shape)\n",
    "print(\"RESULT:\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1CL0Ei5nV_H7"
   },
   "outputs": [],
   "source": [
    "# Seq2Seq 신경망\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "  def __init__(self,\n",
    "                num_encoder_layers: int,\n",
    "                num_decoder_layers: int,\n",
    "                emb_size: int,\n",
    "                nhead: int,\n",
    "                src_vocab_size: int,\n",
    "                tgt_vocab_size: int,\n",
    "                dim_feedforward: int = 512,\n",
    "                dropout: float = 0.1):\n",
    "    super(Seq2SeqTransformer, self).__init__()\n",
    "    self.transformer = nn.Transformer(d_model=emb_size,\n",
    "                                    nhead=nhead,\n",
    "                                    num_encoder_layers=num_encoder_layers,\n",
    "                                    num_decoder_layers=num_decoder_layers,\n",
    "                                    dim_feedforward=dim_feedforward,\n",
    "                                    dropout=dropout)\n",
    "    self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "    self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "    self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "    self.positional_encoding = PositionalEncoding(\n",
    "        emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src,\n",
    "                trg,\n",
    "                src_mask,\n",
    "                tgt_mask,\n",
    "                src_padding_mask,\n",
    "                tgt_padding_mask,\n",
    "                memory_key_padding_mask):\n",
    "      src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "      tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "      outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                              src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "      return self.generator(outs)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "      return self.transformer.encoder(self.positional_encoding(\n",
    "                          self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "      return self.transformer.decoder(self.positional_encoding(\n",
    "                        self.tgt_tok_emb(tgt)), memory,\n",
    "                        tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdtB0IeGmzG3"
   },
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "  mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
    "  mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "  return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1252,
     "status": "ok",
     "timestamp": 1702811603027,
     "user": {
      "displayName": "신은섭",
      "userId": "08402895350193765155"
     },
     "user_tz": -540
    },
    "id": "8nSEScjPv-bB",
    "outputId": "2e060867-76fd-4813-a363-74d4f05d0462"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_square_subsequent_mask(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYHA2dLEv_rN"
   },
   "outputs": [],
   "source": [
    "def create_mask(src, tgt):\n",
    "  src_seq_len = src.shape[0]\n",
    "  tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "  tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "  src_mask = torch.zeros((src_seq_len, src_seq_len),device=device).type(torch.bool)\n",
    "\n",
    "  src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "  tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "  return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1702811603028,
     "user": {
      "displayName": "신은섭",
      "userId": "08402895350193765155"
     },
     "user_tz": -540
    },
    "id": "Sb_k3V8ZwAI5",
    "outputId": "12d684bd-ffc3-4a3f-c691-e61c5f86a9b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False],\n",
       "         [False, False, False, False, False]], device='cuda:0'),\n",
       " tensor([[0., -inf, -inf, -inf, -inf],\n",
       "         [0., 0., -inf, -inf, -inf],\n",
       "         [0., 0., 0., -inf, -inf],\n",
       "         [0., 0., 0., 0., -inf],\n",
       "         [0., 0., 0., 0., 0.]], device='cuda:0'),\n",
       " tensor([[False, False, False,  True,  True]]),\n",
       " tensor([[False, False,  True,  True,  True]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.Tensor([[5], [5], [5], [1], [1]])\n",
    "tgt = torch.Tensor([[5], [5], [1], [1], [1]])\n",
    "create_mask(src, tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTdcPQF7rMxD"
   },
   "source": [
    "### 3.5 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUOK2IeqYNGp"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, epoch, device):\n",
    "  model.train()\n",
    "\n",
    "  running_loss = 0\n",
    "  correct = 0\n",
    "\n",
    "  with tqdm(dataloader) as pbar:\n",
    "    pbar.set_description(f'Epoch - {epoch} TRAIN')\n",
    "    for i, (data, targets) in enumerate(pbar):\n",
    "      data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "      tgt_input = targets[:-1, :]\n",
    "\n",
    "      src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(data, tgt_input)\n",
    "\n",
    "      logits = model(data, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      tgt_out = targets[1:, :]\n",
    "      loss = criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      running_loss += loss.item()\n",
    "      pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    data_num = len(dataloader.dataset)\n",
    "    acc = 100. * correct / data_num\n",
    "\n",
    "    final_loss = running_loss/len(dataloader)\n",
    "    pbar.set_postfix(loss=final_loss)\n",
    "\n",
    "  return final_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYXkMf-4Y0nC"
   },
   "outputs": [],
   "source": [
    "def validation(model, dataloader, criterion, epoch, device):\n",
    "  model.eval()\n",
    "\n",
    "  correct = 0\n",
    "  running_loss = 0.\n",
    "\n",
    "  with tqdm(dataloader) as pbar:\n",
    "    pbar.set_description(f'Epoch - {epoch} VALID')\n",
    "    with torch.no_grad():\n",
    "      for i, (data, targets) in enumerate(pbar):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "        tgt_input = targets[:-1, :]\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(data, tgt_input)\n",
    "\n",
    "        logits = model(data, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = targets[1:, :]\n",
    "        loss = criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "  data_num = len(dataloader.dataset)\n",
    "  acc = 100. * correct / data_num\n",
    "\n",
    "  final_loss = running_loss/len(dataloader)\n",
    "  pbar.set_postfix(loss=final_loss)\n",
    "\n",
    "  return final_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1182725,
     "status": "ok",
     "timestamp": 1702812785750,
     "user": {
      "displayName": "신은섭",
      "userId": "08402895350193765155"
     },
     "user_tz": -540
    },
    "id": "lQaBC0aAhtHn",
    "outputId": "b9cbe42f-a2f5-4851-b438-e7e3d1ef63fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch - 0 TRAIN: 100%|██████████| 1126/1126 [02:38<00:00,  7.12it/s, loss=0.96]\n",
      "Epoch - 0 VALID: 100%|██████████| 141/141 [00:04<00:00, 34.33it/s, loss=1.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model\n",
      "LR: [9.5e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch - 1 TRAIN: 100%|██████████| 1126/1126 [02:39<00:00,  7.05it/s, loss=0.402]\n",
      "Epoch - 1 VALID: 100%|██████████| 141/141 [00:03<00:00, 37.00it/s, loss=0.896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model\n",
      "LR: [9.025e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch - 2 TRAIN: 100%|██████████| 1126/1126 [02:40<00:00,  7.03it/s, loss=0.67]\n",
      "Epoch - 2 VALID: 100%|██████████| 141/141 [00:04<00:00, 34.04it/s, loss=0.734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model\n",
      "LR: [8.573749999999999e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch - 3 TRAIN: 100%|██████████| 1126/1126 [02:41<00:00,  6.96it/s, loss=1.05]\n",
      "Epoch - 3 VALID: 100%|██████████| 141/141 [00:04<00:00, 34.14it/s, loss=0.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model\n",
      "LR: [8.145062499999998e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch - 4 TRAIN: 100%|██████████| 1126/1126 [02:41<00:00,  6.99it/s, loss=0.451]\n",
      "Epoch - 4 VALID: 100%|██████████| 141/141 [00:04<00:00, 35.04it/s, loss=0.754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: [7.737809374999998e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch - 5 TRAIN: 100%|██████████| 1126/1126 [02:40<00:00,  7.00it/s, loss=0.00169]\n",
      "Epoch - 5 VALID: 100%|██████████| 141/141 [00:03<00:00, 36.94it/s, loss=0.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: [7.350918906249998e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch - 6 TRAIN: 100%|██████████| 1126/1126 [02:40<00:00,  7.00it/s, loss=0.145]\n",
      "Epoch - 6 VALID: 100%|██████████| 141/141 [00:03<00:00, 36.37it/s, loss=0.811]\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 7\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 1\n",
    "LR = 0.0001\n",
    "\n",
    "trainset, valset, testset = get_dataset()\n",
    "\n",
    "# dataloader\n",
    "train_loader = DataLoader(\n",
    "  dataset=trainset,\n",
    "  shuffle=True,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  num_workers=NUM_WORKERS,\n",
    "  collate_fn=collate_fn\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "  dataset=valset,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  num_workers=NUM_WORKERS,\n",
    "  collate_fn=collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "  dataset=testset,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  num_workers=NUM_WORKERS,\n",
    "  collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# model\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "SRC_VOCAB_SIZE = len(text_vocab)\n",
    "TGT_VOCAB_SIZE = len(ner_vocab)\n",
    "FFN_HID_DIM = 512\n",
    "DROPOUT = 0.2\n",
    "\n",
    "model = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                           NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM, DROPOUT)\n",
    "\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "# Optimizer, Loss, Scheduler\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "min_loss = 999\n",
    "# Start Training\n",
    "for epoch in range(EPOCH):\n",
    "  print(\"LR:\", scheduler.get_last_lr())\n",
    "\n",
    "  start_time = timer()\n",
    "  tloss, tacc = train(model, train_loader, criterion, optimizer, epoch, device)\n",
    "  end_time = timer()\n",
    "\n",
    "  start_time = timer()\n",
    "  vloss, vacc = validation(model, val_loader, criterion, epoch, device)\n",
    "  end_time = timer()\n",
    "\n",
    "  scheduler.step()\n",
    "\n",
    "  if vloss < min_loss:\n",
    "    min_loss = vloss\n",
    "    torch.save(model.state_dict(), \"best.pth\")\n",
    "    print(\"save model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqKX0Pskx1Ce"
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "  src = src.to(device)\n",
    "  src_mask = src_mask.to(device)\n",
    "\n",
    "  memory = model.encode(src, src_mask)\n",
    "  ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
    "\n",
    "  for i in range(max_len-1):\n",
    "    memory = memory.to(device)\n",
    "    tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                .type(torch.bool)).to(device)\n",
    "    out = model.decode(ys, memory, tgt_mask)\n",
    "    out = out.transpose(0, 1)\n",
    "    prob = model.generator(out[:, -1])\n",
    "    _, next_word = torch.max(prob, dim=1)\n",
    "    next_word = next_word.item()\n",
    "\n",
    "    ys = torch.cat([ys,\n",
    "                    torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "    if next_word == EOS_IDX:\n",
    "      break\n",
    "  return ys\n",
    "\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "  model.eval()\n",
    "  src = text_transforms(src_sentence).view(-1, 1)\n",
    "  num_tokens = src.shape[0]\n",
    "  src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "  tgt_tokens = greedy_decode(\n",
    "    model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "  return \" \".join(\n",
    "      ner_vocab.lookup_tokens(list(tgt_tokens.cpu().numpy()))\n",
    "    ).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2125,
     "status": "ok",
     "timestamp": 1702813298281,
     "user": {
      "displayName": "신은섭",
      "userId": "08402895350193765155"
     },
     "user_tz": -540
    },
    "id": "wolq6WN74cbQ",
    "outputId": "3e17cdcc-f23b-4a7b-fea6-aae66fe9b800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DAT_B DAT_I LOC_B EVT_B - - \n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best.pth\"))\n",
    "tokenizer = get_tokenizer(\"spacy\", \"ko_core_news_sm\")\n",
    "print(translate(model, tokenizer(\"12월 25일 부산에서 아시안게임 개최 논의\")))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMbx3SSF6MjVgyZc6t9g5i8",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
